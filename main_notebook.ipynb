{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8V6Zu3LhYqft"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def create_subsampled_dataset(source_dir, target_dir, max_samples_per_class=100):\n",
        "    \"\"\"\n",
        "    Create a subsampled dataset where each class has up to max_samples_per_class samples.\n",
        "    \"\"\"\n",
        "    # Ensure the target directory exists\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "    for class_name in os.listdir(source_dir):\n",
        "        class_dir = os.path.join(source_dir, class_name)\n",
        "        if not os.path.isdir(class_dir):\n",
        "            continue\n",
        "\n",
        "        target_class_dir = os.path.join(target_dir, class_name)\n",
        "        os.makedirs(target_class_dir, exist_ok=True)\n",
        "\n",
        "        # Get all file names for this class\n",
        "        all_files = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))]\n",
        "        # Randomly select up to max_samples_per_class files\n",
        "        sampled_files = random.sample(all_files, min(max_samples_per_class, len(all_files)))\n",
        "\n",
        "        # Copy the selected files to the target directory\n",
        "        for file_name in sampled_files:\n",
        "            shutil.copy(os.path.join(class_dir, file_name), os.path.join(target_class_dir, file_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CykKcBbsM_sH",
        "outputId": "0db57a2f-fa02-40cc-dbd0-842174e0f8db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD 0\n",
            "--------------------------------\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 1.5091 Acc: 0.3999\n",
            "val Loss: 1.2771 Acc: 0.4762\n",
            "New best model saved at epoch 1 with loss 1.2771, acc 0.4762\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 1.3082 Acc: 0.4812\n",
            "val Loss: 1.2400 Acc: 0.4724\n",
            "New best model saved at epoch 2 with loss 1.2400, acc 0.4724\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 1.2510 Acc: 0.5047\n",
            "val Loss: 1.1963 Acc: 0.5063\n",
            "New best model saved at epoch 3 with loss 1.1963, acc 0.5063\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 1.2030 Acc: 0.5207\n",
            "val Loss: 1.1568 Acc: 0.5141\n",
            "New best model saved at epoch 4 with loss 1.1568, acc 0.5141\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 1.1626 Acc: 0.5278\n",
            "val Loss: 1.1253 Acc: 0.5112\n",
            "New best model saved at epoch 5 with loss 1.1253, acc 0.5112\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 1.1518 Acc: 0.5411\n",
            "val Loss: 1.1325 Acc: 0.5257\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 1.1171 Acc: 0.5331\n",
            "val Loss: 1.0995 Acc: 0.5519\n",
            "New best model saved at epoch 7 with loss 1.0995, acc 0.5519\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 1.0954 Acc: 0.5654\n",
            "val Loss: 1.1099 Acc: 0.5529\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 1.0806 Acc: 0.5652\n",
            "val Loss: 1.1209 Acc: 0.5335\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 1.0667 Acc: 0.5605\n",
            "val Loss: 1.1410 Acc: 0.5713\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 1.0403 Acc: 0.5749\n",
            "val Loss: 1.0700 Acc: 0.5761\n",
            "New best model saved at epoch 11 with loss 1.0700, acc 0.5761\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 1.0123 Acc: 0.5931\n",
            "val Loss: 1.1308 Acc: 0.5422\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.9922 Acc: 0.6020\n",
            "val Loss: 1.0921 Acc: 0.5567\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.9880 Acc: 0.5933\n",
            "val Loss: 1.1005 Acc: 0.5548\n",
            "Training complete in 10m 56s\n",
            "Best val Loss: 1.0700, Best val Acc: 0.5761\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 1.4731 Acc: 0.4055\n",
            "val Loss: 1.3084 Acc: 0.4491\n",
            "New best model saved at epoch 1 with loss 1.3084, acc 0.4491\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 1.3064 Acc: 0.4691\n",
            "val Loss: 1.2509 Acc: 0.4879\n",
            "New best model saved at epoch 2 with loss 1.2509, acc 0.4879\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 1.2360 Acc: 0.5052\n",
            "val Loss: 1.2181 Acc: 0.5024\n",
            "New best model saved at epoch 3 with loss 1.2181, acc 0.5024\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 1.2076 Acc: 0.5057\n",
            "val Loss: 1.2266 Acc: 0.5102\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 1.1812 Acc: 0.5268\n",
            "val Loss: 1.1700 Acc: 0.5179\n",
            "New best model saved at epoch 5 with loss 1.1700, acc 0.5179\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 1.1445 Acc: 0.5355\n",
            "val Loss: 1.2037 Acc: 0.5179\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 1.1237 Acc: 0.5501\n",
            "val Loss: 1.2836 Acc: 0.4811\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 1.0803 Acc: 0.5533\n",
            "val Loss: 1.1653 Acc: 0.5286\n",
            "New best model saved at epoch 8 with loss 1.1653, acc 0.5286\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 1.0675 Acc: 0.5603\n",
            "val Loss: 1.1681 Acc: 0.5179\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 1.0512 Acc: 0.5807\n",
            "val Loss: 1.1504 Acc: 0.5315\n",
            "New best model saved at epoch 10 with loss 1.1504, acc 0.5315\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 1.0078 Acc: 0.5790\n",
            "val Loss: 1.1497 Acc: 0.5529\n",
            "New best model saved at epoch 11 with loss 1.1497, acc 0.5529\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 1.0128 Acc: 0.5938\n",
            "val Loss: 1.1754 Acc: 0.5383\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.9937 Acc: 0.6042\n",
            "val Loss: 1.1657 Acc: 0.5325\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.9645 Acc: 0.6086\n",
            "val Loss: 1.1678 Acc: 0.5315\n",
            "Training complete in 11m 25s\n",
            "Best val Loss: 1.1497, Best val Acc: 0.5529\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 1.4872 Acc: 0.3935\n",
            "val Loss: 1.3506 Acc: 0.4641\n",
            "New best model saved at epoch 1 with loss 1.3506, acc 0.4641\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 1.3053 Acc: 0.4748\n",
            "val Loss: 1.2567 Acc: 0.5029\n",
            "New best model saved at epoch 2 with loss 1.2567, acc 0.5029\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 1.2474 Acc: 0.4968\n",
            "val Loss: 1.2627 Acc: 0.4961\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 1.1903 Acc: 0.5150\n",
            "val Loss: 1.2769 Acc: 0.5087\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 1.1542 Acc: 0.5298\n",
            "val Loss: 1.1701 Acc: 0.5379\n",
            "New best model saved at epoch 5 with loss 1.1701, acc 0.5379\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 1.1316 Acc: 0.5311\n",
            "val Loss: 1.1797 Acc: 0.5301\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 1.0756 Acc: 0.5699\n",
            "val Loss: 1.1589 Acc: 0.5592\n",
            "New best model saved at epoch 7 with loss 1.1589, acc 0.5592\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 1.0703 Acc: 0.5667\n",
            "val Loss: 1.2145 Acc: 0.5223\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 1.0537 Acc: 0.5696\n",
            "val Loss: 1.2240 Acc: 0.5398\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 1.0178 Acc: 0.5818\n",
            "val Loss: 1.1612 Acc: 0.5282\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.9958 Acc: 0.5890\n",
            "val Loss: 1.2297 Acc: 0.5437\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.9841 Acc: 0.5973\n",
            "val Loss: 1.1542 Acc: 0.5437\n",
            "New best model saved at epoch 12 with loss 1.1542, acc 0.5437\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.9703 Acc: 0.6050\n",
            "val Loss: 1.1125 Acc: 0.5505\n",
            "New best model saved at epoch 13 with loss 1.1125, acc 0.5505\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.9350 Acc: 0.6177\n",
            "val Loss: 1.2080 Acc: 0.5204\n",
            "Training complete in 11m 25s\n",
            "Best val Loss: 1.1125, Best val Acc: 0.5505\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 1.4730 Acc: 0.3984\n",
            "val Loss: 1.2731 Acc: 0.4893\n",
            "New best model saved at epoch 1 with loss 1.2731, acc 0.4893\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 1.3152 Acc: 0.4719\n",
            "val Loss: 1.2529 Acc: 0.5107\n",
            "New best model saved at epoch 2 with loss 1.2529, acc 0.5107\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 1.2493 Acc: 0.4905\n",
            "val Loss: 1.1879 Acc: 0.5049\n",
            "New best model saved at epoch 3 with loss 1.1879, acc 0.5049\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 1.1952 Acc: 0.5143\n",
            "val Loss: 1.1733 Acc: 0.5301\n",
            "New best model saved at epoch 4 with loss 1.1733, acc 0.5301\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 1.1612 Acc: 0.5267\n",
            "val Loss: 1.2036 Acc: 0.5126\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 1.1513 Acc: 0.5213\n",
            "val Loss: 1.0662 Acc: 0.5612\n",
            "New best model saved at epoch 6 with loss 1.0662, acc 0.5612\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 1.1212 Acc: 0.5432\n",
            "val Loss: 1.1262 Acc: 0.5282\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 1.0832 Acc: 0.5563\n",
            "val Loss: 1.1752 Acc: 0.5359\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 1.0746 Acc: 0.5638\n",
            "val Loss: 1.1057 Acc: 0.5388\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 1.0417 Acc: 0.5745\n",
            "val Loss: 1.1637 Acc: 0.5534\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 1.0388 Acc: 0.5818\n",
            "val Loss: 1.0794 Acc: 0.5631\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 1.0097 Acc: 0.5958\n",
            "val Loss: 1.1931 Acc: 0.5485\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.9535 Acc: 0.6077\n",
            "val Loss: 1.0860 Acc: 0.5689\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.9422 Acc: 0.6235\n",
            "val Loss: 1.0870 Acc: 0.5699\n",
            "Training complete in 11m 26s\n",
            "Best val Loss: 1.0662, Best val Acc: 0.5612\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 1.5068 Acc: 0.3954\n",
            "val Loss: 1.3691 Acc: 0.4282\n",
            "New best model saved at epoch 1 with loss 1.3691, acc 0.4282\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 1.3059 Acc: 0.4677\n",
            "val Loss: 1.3048 Acc: 0.4631\n",
            "New best model saved at epoch 2 with loss 1.3048, acc 0.4631\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 1.2392 Acc: 0.5015\n",
            "val Loss: 1.2758 Acc: 0.4874\n",
            "New best model saved at epoch 3 with loss 1.2758, acc 0.4874\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 1.1958 Acc: 0.5167\n",
            "val Loss: 1.2333 Acc: 0.5087\n",
            "New best model saved at epoch 4 with loss 1.2333, acc 0.5087\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 1.1763 Acc: 0.5150\n",
            "val Loss: 1.1733 Acc: 0.5301\n",
            "New best model saved at epoch 5 with loss 1.1733, acc 0.5301\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 1.1237 Acc: 0.5403\n",
            "val Loss: 1.1878 Acc: 0.5136\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 1.1188 Acc: 0.5507\n",
            "val Loss: 1.2345 Acc: 0.5136\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 1.0857 Acc: 0.5604\n",
            "val Loss: 1.1952 Acc: 0.5126\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 1.0725 Acc: 0.5708\n",
            "val Loss: 1.2337 Acc: 0.5272\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 1.0538 Acc: 0.5721\n",
            "val Loss: 1.1373 Acc: 0.5408\n",
            "New best model saved at epoch 10 with loss 1.1373, acc 0.5408\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 1.0140 Acc: 0.5869\n",
            "val Loss: 1.1689 Acc: 0.5262\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.9953 Acc: 0.5949\n",
            "val Loss: 1.1926 Acc: 0.5301\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.9943 Acc: 0.5983\n",
            "val Loss: 1.1858 Acc: 0.5282\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.9414 Acc: 0.6327\n",
            "val Loss: 1.1661 Acc: 0.5398\n",
            "Training complete in 11m 29s\n",
            "Best val Loss: 1.1373, Best val Acc: 0.5408\n",
            "\n",
            "Final evaluation on the test set:\n",
            "\n",
            "Test set: Average loss: 1.0933, Accuracy: 0.5450\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries from PyTorch for model building, optimization, and data manipulation\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "\n",
        "# Setting a seed for reproducibility\n",
        "np.random.seed(123)\n",
        "\n",
        "# Customizing the ResNet50 model for a classification task with a specified number of classes\n",
        "class ResNet50Custom(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        \"\"\"Customized ResNet50 as given in section 4.4 of the report\"\"\"\n",
        "        super(ResNet50Custom, self).__init__()\n",
        "        # Loading the pre-trained ResNet50 model\n",
        "        self.base_model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "        # Getting the number of features of the last layer\n",
        "        num_ftrs = self.base_model.fc.in_features\n",
        "        # Replacing the last fully connected layer with a new one that matches the number of classes\n",
        "        # Adding dropout for regularization, as mentioned in section 4.3 of the report\n",
        "        self.base_model.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_ftrs, num_classes)\n",
        "        )\n",
        "\n",
        "    # Forward pass definition\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Function to evaluate the model's performance on a dataset\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    model.eval()  # Switching the model to evaluation mode\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total = 0\n",
        "\n",
        "    # Iterating over batches of data in the specified DataLoader\n",
        "    for inputs, labels in data_loader:\n",
        "        inputs = inputs.to(device)  # Moving inputs to the device\n",
        "        labels = labels.to(device)  # Moving labels to the device\n",
        "\n",
        "        # Forward pass without gradient calculation\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)  # Getting the predicted labels\n",
        "            loss = criterion(outputs, labels)  # Calculating the loss\n",
        "\n",
        "        # Accumulating the loss and the number of correct predictions\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        total += labels.size(0)\n",
        "\n",
        "    # Calculating average loss and accuracy\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = running_corrects.double() / total\n",
        "\n",
        "    # Printing loss and accuracy\n",
        "    print(f'\\nTest set: Average loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\\n')\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs, device, fold):\n",
        "    \"\"\" Function to train the model, takes the instantiated model,\n",
        "    loss function, optimizer, scheduler to lower learning rate,\n",
        "    train and validations sets, number of epochs, device and current kth fold\"\"\"\n",
        "    since = time.time()  # To measure the duration of the training\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())  # Copying the model's initial weights for checkpointing\n",
        "    best_acc = 0.0  # Best accuracy initialization\n",
        "    lowest_val_loss = float('inf')  # Lowest validation loss initialization\n",
        "\n",
        "    # Looping through each epoch\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Training and validation phase for each epoch\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Setting the model to training mode\n",
        "            else:\n",
        "                model.eval()   # Setting the model to evaluation mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterating over data for the current phase\n",
        "            data_loader = train_loader if phase == 'train' else val_loader\n",
        "            for inputs, labels in data_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass. Track gradients if in train phase\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backward pass + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics accumulation\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # Epoch statistics calculation\n",
        "            epoch_loss = running_loss / len(data_loader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(data_loader.dataset)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # Checkpointing the model if it has the lowest validation loss so far, as given in section 4.4 of the report\n",
        "            if phase == 'val' and epoch_loss < lowest_val_loss:\n",
        "                lowest_val_loss = epoch_loss\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                # Saving the model state dict with the best validation accuracy\n",
        "                torch.save(model.state_dict(), f'model_best_val_fold_{fold}.pth')\n",
        "                print(f\"New best model saved at epoch {epoch+1} with loss {lowest_val_loss:.4f}, acc {best_acc:.4f}\")\n",
        "\n",
        "    # Printing the training time\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print(f'Best val Loss: {lowest_val_loss:.4f}, Best val Acc: {best_acc:.4f}')\n",
        "\n",
        "    # Loading the best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# The main function initializes and trains the model, also evaluates it on the test set.\n",
        "def main():\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # Setting the device\n",
        "    num_epochs = 14  # Number of epochs to train\n",
        "    k_folds = 5  # Number of folds for K-Fold Cross-Validation\n",
        "    num_classes = 7  # Number of classes in the dataset\n",
        "\n",
        "    # Defining transformations for data augmentation and normalization\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "\n",
        "    source = 'data'  # Source directory of the dataset\n",
        "    data_dir = 'subsampling'  # Directory where the undersampled dataset will be stored\n",
        "    create_subsampled_dataset(source, data_dir, 1000)  # Function call to create a subsampled dataset with 1000 random samples from each class\n",
        "    full_dataset = datasets.ImageFolder(data_dir)  # Loading the dataset\n",
        "\n",
        "    # Splitting the dataset into training/validation and testing sets\n",
        "    train_val_indices, test_indices = train_test_split(range(len(full_dataset)), test_size=0.2, random_state=123)\n",
        "\n",
        "    # Creating datasets for training/validation and testing phases with their respective transformations\n",
        "    train_val_dataset = datasets.ImageFolder(data_dir, transform=data_transforms['train'])\n",
        "    test_dataset = datasets.ImageFolder(data_dir, transform=data_transforms['val'])\n",
        "\n",
        "    # Creating DataLoaders for the train/validation and test subsets\n",
        "    train_val_subset = Subset(train_val_dataset, train_val_indices)\n",
        "    test_subset = Subset(test_dataset, test_indices)\n",
        "    test_loader = DataLoader(test_subset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Performing K-Fold Cross-Validation\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
        "    for fold, (train_ids, val_ids) in enumerate(kfold.split(train_val_subset)):\n",
        "        print(f'FOLD {fold}')\n",
        "        print('--------------------------------')\n",
        "\n",
        "        # Creating DataLoaders for each fold\n",
        "        train_subsampler = Subset(train_val_subset, train_ids)\n",
        "        val_subsampler = Subset(train_val_subset, val_ids)\n",
        "        # Setting batch sizes to 32 as describe in section 4.5 of the report\n",
        "        train_loader = DataLoader(train_subsampler, batch_size=32, shuffle=True, num_workers=4)\n",
        "        val_loader = DataLoader(val_subsampler, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "        # Model initialization\n",
        "        model = ResNet50Custom(num_classes).to(device)\n",
        "        # Stochastic Gradient Descent (SGD) optimizer as mention in section 4.4 of the report\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "        # Learning rate scheduler for adaptive learning rate adjustments, as mention in section 4.4 of the report\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
        "        # Cross-Entropy Loss with class weights to handle imbalanced datasets\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Model training and validation for the current fold\n",
        "        model_ft = train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs, device, fold)\n",
        "\n",
        "    # Final model evaluation on the test set\n",
        "    print(\"\\nFinal evaluation on the test set:\")\n",
        "    test_loss, test_acc = evaluate_model(model_ft, test_loader, criterion, device)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
